name: Train Stock Screener Model (XGBoost)

on:
  schedule:
    # Run weekly on Sunday at 02:00 UTC (Saturday 9 PM ET / Sunday 10 PM ET)
    # Model is stable week-to-week; weekly retraining is sufficient
    # This ensures fresh model for Monday trading
    - cron: '0 2 * * 0'
  workflow_dispatch:

jobs:
  train_model:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements-actions.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Cache universe/data/models
        id: cache_model_data
        uses: actions/cache@v4
        with:
          path: |
            cache/
            data_cache/
            models/
          key: ${{ runner.os }}-screener-model-${{ hashFiles('requirements-actions.txt', '.github/workflows/train-stock-screener-model.yml') }}
          restore-keys: |
            ${{ runner.os }}-screener-model-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-actions.txt

      - name: Show system resources
        run: |
          echo "=== Memory ==="
          free -h
          echo "=== CPU ==="
          nproc
          echo "=== Disk ==="
          df -h
      
      - name: Train model
        env:
          MODEL_PATH: "models/ensemble/manifest.json"
          LABEL_HORIZON_DAYS: "5"
          # Full universe for better signal
          MAX_TICKERS: "4000"
          FEATURE_LOOKBACK_DAYS: "730"
          BATCH_SIZE: "250"
          # Quality filters â€” train only on investable stocks
          MIN_PRICE_CAD: "5.0"
          MIN_AVG_DOLLAR_VOLUME_CAD: "5000000"
          MAX_SCREEN_VOLATILITY: "0.80"
          # Optuna tuning (8 trials is sufficient; marginal gains diminish fast)
          OPTUNA_N_TRIALS: "8"
          OPTUNA_TIMEOUT_SECONDS: "120"
          # 2 XGB + 2 LightGBM = 4 diverse models (good quality/speed trade-off)
          ENSEMBLE_XGB_COUNT: "2"
          ENSEMBLE_LGBM_COUNT: "2"
          # PR-04: Regime specialists + gating
          REGIME_SPECIALIST_ENABLED: "1"
          REGIME_SPECIALIST_MIN_SAMPLES: "1200"
          REGIME_GATING_BASE_BLEND: "0.25"
          # PR-06: Promotion gates (block deployment if failed)
          PROMOTION_GATES_ENABLED: "1"
          # Keep training job green on non-promotions by default; artifact upload is gated below.
          # Set repo var ENFORCE_PROMOTION_GATES=1 to restore hard-fail behavior.
          ENFORCE_PROMOTION_GATES: ${{ vars.ENFORCE_PROMOTION_GATES || '0' }}
          PROMOTION_MIN_RETURN_PER_DAY: "0.0002"
          PROMOTION_MIN_COST_ADJUSTED_SHARPE: "0.5"
          PROMOTION_MAX_DRAWDOWN: "-0.25"
          PROMOTION_MIN_CONSISTENCY: "0.55"
          PROMOTION_MIN_TURNOVER_EFFICIENCY: "0.20"
          PROMOTION_MAX_AVG_TURNOVER: "0.80"
          # Reduce unnecessary rebalance churn in promotion simulation.
          PROMOTION_REBALANCE_HYSTERESIS: ${{ vars.PROMOTION_REBALANCE_HYSTERESIS || '0.35' }}
          # Cap one-step turnover during promotion simulation.
          PROMOTION_MAX_TURNOVER_PER_REBALANCE: ${{ vars.PROMOTION_MAX_TURNOVER_PER_REBALANCE || '0.75' }}
          PROMOTION_MIN_PERIODS: "2"
          PROMOTION_MAX_CALIBRATION_ERROR: ${{ vars.PROMOTION_MAX_CALIBRATION_ERROR || '0.010' }}
          PROMOTION_MIN_CALIBRATION_SLOPE: ${{ vars.PROMOTION_MIN_CALIBRATION_SLOPE || '0.25' }}
          PROMOTION_MAX_PBO_PROXY: ${{ vars.PROMOTION_MAX_PBO_PROXY || '0.45' }}
          # Use calibrated base predictions for promotion scoring unless explicitly overridden.
          PROMOTION_USE_QUANTILE_LCB: ${{ vars.PROMOTION_USE_QUANTILE_LCB || '0' }}
          PREDICTION_RECALIBRATION_ENABLED: ${{ vars.PREDICTION_RECALIBRATION_ENABLED || '1' }}
          APPLY_PREDICTION_RECALIBRATION: ${{ vars.APPLY_PREDICTION_RECALIBRATION || '1' }}
        run: |
          rm -rf models/ensemble
          python -m stock_screener.cli train-model --log-level INFO

      - name: Evaluate promotion gate result
        id: promotion_gates
        run: |
          python - <<'PY'
          import json
          import os
          from pathlib import Path

          metrics_path = Path("models/ensemble/metrics.json")
          passed = False

          if metrics_path.exists():
              data = json.loads(metrics_path.read_text(encoding="utf-8"))
              promotion = data.get("promotion_gates") or {}
              passed = bool(promotion.get("passed", False))
          else:
              print("::warning::metrics.json not found; treating as not promoted.")

          print(f"Promotion gates passed: {passed}")
          with open(os.environ["GITHUB_OUTPUT"], "a", encoding="utf-8") as fh:
              fh.write(f"passed={'true' if passed else 'false'}\n")

          if not passed:
              print("::warning::Model did not pass promotion gates; artifact upload will be skipped.")
          PY

      - name: Upload trained model artifact
        if: success() && steps.promotion_gates.outputs.passed == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: screener-model-${{ github.run_number }}
          path: |
            models/ensemble/
          retention-days: 90
